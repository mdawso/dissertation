# $Id: references.bib 1789 2010-09-28 16:30:23Z jabriffa $

# This file contains bibliography entries in BibTeX format. Examples are
# provided of the more common entry types.

@MISC{wiki_ai_games,
    title = {Artificial intelligence in video games},
    author = {Wikipedia},
    howpublished = {\url{https://en.wikipedia.org/wiki/Artificial_intelligence_in_video_games}},
    year = {2025},
    note = {Accessed: 12/04/25}
}



@MISC{simulacrum,
    title = {Simulacrum: Building Believable Behaviors in Video Game AI},
    author = {Sean Carpenter},
    howpublished = {\url{https://medium.com/@selcarpe/https-medium-com-simulacrum-28477a0e759e}},
    year = {2019},
    note = {Accessed: 12/04/25}
}

@MISC{keras_dqn_breakout,
    title = {Deep {Q}-Learning for Atari Breakout},
    author = {Keras},
    howpublished = {\url{https://keras.io/examples/rl/deep_q_network_breakout/}},
    year = {2023},
    note = {Accessed: 13/04/25}
}

@MISC{deepmind_alphago,
    title = {AlphaGo},
    author = {DeepMind},
    howpublished = {\url{https://deepmind.google/research/breakthroughs/alphago/}},
    year = {2023},
    note = {Accessed: 13/04/25}
}

@MISC{fsms,
    title = {Finite State Machines},
    author = {ilkinulas},
    howpublished = {\url{https://ilkinulas.github.io/development/general/2016/04/23/finite-state-machines.html}},
    year = {2016},
    note = {Accessed: 14/04/25}
}

@MISC{simpson2014behaviortrees,
    title = {Behavior Trees for AI: How They Work},
    author = {Chris Simpson},
    howpublished = {\url{https://www.gamedeveloper.com/programming/behavior-trees-for-ai-how-they-work}},
    year = {2014},
    note = {Accessed: 12/04/25}
}

@MISC{gamedevelopertips_fsm,
    title = {Finite State Machine For Game Developers},
    author = {Marco},
    howpublished = {\url{https://gamedevelopertips.com/finite-state-machine-game-developers/}},
    year = {2025},
    note = {Accessed: 14/04/25}
}

@MISC{crashkonijn_goap,
    title = {Goal Oriented Action Planning - Theory},
    author = {Crashkonijn},
    howpublished = {\url{https://goap.crashkonijn.com/readme/theory}},
    year = {2024},
    note = {Accessed: 17/04/25}
}

@MISC{thompson2020fear,
    title = {Building the AI of F.E.A.R. with Goal-Oriented Action Planning},
    author = {Tommy Thompson},
    howpublished = {\url{https://www.gamedeveloper.com/design/building-the-ai-of-f-e-a-r-with-goal-oriented-action-planning}},
    year = {2020},
    note = {Accessed: 17/04/25}
}

@MISC{spiceworks_fsm,
    title = {What Is Finite State Machine (FSM)?},
    author = {Vijay Kanade},
    year = {2021},
    howpublished = {\url{https://www.spiceworks.com/tech/tech-general/articles/what-is-fsm/}},
    note = {Accessed: 17/04/25}
}

@ARTICLE{colledanchise2017behaviortrees,
    title = {Behavior Trees for Computer Games},
    author = {Yoones A. Sekhavat},
    journal = {International Journal of Artificial Intelligence Tools},
    year = {2017},
    howpublished = {\url{https://www.researchgate.net/publication/312869797_Behavior_Trees_for_Computer_Games}},
    note = {Accessed: 12/04/25}
}

@MISC{cornell_mdp,
    title = {Markov decision process},
    author = {Eric Berg},
    howpublished = {\url{https://optimization.cbe.cornell.edu/index.php?title=Markov_decision_process}},
    year = {2020},
    note = {Accessed: 18/04/25}
}

@MISC{shao2019surveydeepreinforcementlearning,
    title={A Survey of Deep Reinforcement Learning in Video Games}, 
    author={Kun Shao and Zhentao Tang and Yuanheng Zhu and Nannan Li and Dongbin Zhao},
    year={2019},
    eprint={1912.10944},
    archivePrefix={arXiv},
    primaryClass={cs.MA},
    url={https://arxiv.org/abs/1912.10944}, 
}

@MISC{openai_spinningup_rl,
    title = {Spinning Up Part 2: Kinds of RL Algorithms},
    author = {OpenAI},
    howpublished = {\url{https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html}},
    year = {2025},
    note = {Accessed: 18/04/25}
}

@MISC{li2018deepreinforcementlearning,
    title={Deep Reinforcement Learning: An Overview},
    author={Yuxi Li},
    year={2018},
    eprint={1810.06339},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/1810.06339}
}

@MISC{scs2018exploration,
    title={Experience Replay for Continual Learning},
    author={David Rolnick, Arun Ahuja, Jonathan Schwarz and Timothy P. Lillicrap and Greg Wayne},
    year={2018},
    eprint={1811.11682},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/1811.11682}
}

@MISC{singh2019reinforcementlearning,
    title={RBED: Reward Based Epsilon Decay},
    author={Aakash Maroti},
    year={2019},
    eprint={1910.13701},
    archivePrefix={arXiv},
    primaryClass={q-fin.ST},
    url={https://arxiv.org/abs/1910.13701}
}

@MISC{geeksforgeeks_bellman,
    title = {Bellman Equation},
    author = {GeeksforGeeks},
    howpublished = {\url{https://www.geeksforgeeks.org/bellman-equation/}},
    year = {2025},
    note = {Accessed: 18/04/25}
}

@ARTICLE{app13042443,
    AUTHOR = {Souchleris, Konstantinos and Sidiropoulos, George K. and Papakostas, George A.},
    TITLE = {Reinforcement Learning in Game Industry—Review, Prospects and Challenges},
    JOURNAL = {Applied Sciences},
    VOLUME = {13},
    YEAR = {2023},
    NUMBER = {4},
    ARTICLE-NUMBER = {2443},
    URL = {https://www.mdpi.com/2076-3417/13/4/2443},
    ISSN = {2076-3417},
    ABSTRACT = {This article focuses on the recent advances in the field of reinforcement learning (RL) as well as the present state–of–the–art applications in games. First, we give a general panorama of RL while at the same time we underline the way that it has progressed to the current degree of application. Moreover, we conduct a keyword analysis of the literature on deep learning (DL) and reinforcement learning in order to analyze to what extent the scientific study is based on games such as ATARI, Chess, and Go. Finally, we explored a range of public data to create a unified framework and trends for the present and future of this sector (RL in games). Our work led us to conclude that deep RL accounted for roughly 25.1% of the DL literature, and a sizable amount of this literature focuses on RL applications in the game domain, indicating the road for newer and more sophisticated algorithms capable of outperforming human performance.},
    DOI = {10.3390/app13042443}
}
